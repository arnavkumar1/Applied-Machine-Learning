{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import math\n",
    "from sklearn import preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"train.csv\",sep=',')\n",
    "df['taxi_type']=df['taxi_type'].fillna(df['taxi_type'].value_counts().idxmax())\n",
    "df['months_of_activity'] = df['months_of_activity'].fillna(df['months_of_activity'].mean())\n",
    "df['customer_score'] = df['customer_score'].fillna(df['customer_score'].mean())\n",
    "df['customer_score_confidence'] = df['customer_score_confidence'].fillna(df['customer_score_confidence'].value_counts().idxmax())\n",
    "df['drop_location_type'] = df['drop_location_type'].fillna(df['drop_location_type'].value_counts().idxmax())\n",
    "df['ratings_given_by_cust'] = df['ratings_given_by_cust'].fillna(df['ratings_given_by_cust'].mean())\n",
    "df['num_of_cancelled_trips'] = df['num_of_cancelled_trips'].fillna(math.ceil(df['num_of_cancelled_trips'].mean()))\n",
    "df['anon_var_1'] = df['anon_var_1'].fillna(math.ceil(df['anon_var_1'].mean()))\n",
    "df['anon_var_2'] = df['anon_var_2'].fillna(math.ceil(df['anon_var_2'].mean()))\n",
    "df['anon_var_3'] = df['anon_var_3'].fillna(math.ceil(df['anon_var_3'].mean()))\n",
    "df['sex'] = df['sex'].map({'Female': 1, 'Male': 0})\n",
    "abc = df['taxi_type'].unique()\n",
    "df['taxi_type'] = df['taxi_type'].map({'A':0, 'B':1, 'C':2, 'D':3, 'E':4})\n",
    "customer_score_confidence = df['customer_score_confidence'].unique()\n",
    "customer_score_confidence.sort()\n",
    "df['customer_score_confidence'] = df['customer_score_confidence'].map({customer_score_confidence[i]:i for i in range(len(customer_score_confidence))})\n",
    "drop_location_type = df['drop_location_type'].unique()\n",
    "drop_location_type.sort()\n",
    "#print(drop_location_type)\n",
    "df['drop_location_type'] = df['drop_location_type'].map({drop_location_type[i]:i for i in range(len(drop_location_type))})\n",
    "\n",
    "df = df.drop(['id'],axis=1)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf=pd.read_csv(\"test.csv\",sep=\",\")\n",
    "tf['taxi_type']=tf['taxi_type'].fillna('B')\n",
    "tf['months_of_activity'] = tf['months_of_activity'].fillna(df['months_of_activity'].mean())\n",
    "tf['customer_score'] = tf['customer_score'].fillna(df['customer_score'].mean())\n",
    "tf['customer_score_confidence'] = tf['customer_score_confidence'].fillna('B')\n",
    "tf['drop_location_type'] = tf['drop_location_type'].fillna('A')\n",
    "tf['ratings_given_by_cust'] = tf['ratings_given_by_cust'].fillna(df['ratings_given_by_cust'].mean())\n",
    "tf['num_of_cancelled_trips'] = tf['num_of_cancelled_trips'].fillna(math.ceil(df['num_of_cancelled_trips'].mean()))\n",
    "tf['anon_var_1'] = tf['anon_var_1'].fillna(math.ceil(df['anon_var_1'].mean())).astype(int)\n",
    "tf['anon_var_2'] = tf['anon_var_2'].fillna(math.ceil(df['anon_var_2'].mean()))\n",
    "tf['anon_var_3'] = tf['anon_var_3'].fillna(math.ceil(df['anon_var_3'].mean()))\n",
    "\n",
    "# taxi_type = df['taxi_type'].unique()\n",
    "# taxi_type.sort()\n",
    "# df['taxi_type'] = df['taxi_type'].map({taxi_type[i]:i for i in range(len(taxi_type))})\n",
    "\n",
    "\n",
    "tf['taxi_type'] = tf['taxi_type'].map({'A':0, 'B':1, 'C':2, 'D':3, 'E':4})\n",
    "tf['sex'] = tf['sex'].map({'Female': 1, 'Male': 0})\n",
    "customer_score_confidence = tf['customer_score_confidence'].unique()\n",
    "# customer_score_confidence = customer_score_confidence[~(pd.isnull(customer_score_confidence))]\n",
    "customer_score_confidence.sort()\n",
    "tf['customer_score_confidence'] = tf['customer_score_confidence'].map({customer_score_confidence[i]:i for i in range(len(customer_score_confidence))})\n",
    "drop_location_type = tf['drop_location_type'].unique()\n",
    "drop_location_type.sort()\n",
    "#print(drop_location_type)\n",
    "tf['drop_location_type'] = tf['drop_location_type'].map({drop_location_type[i]:i for i in range(len(drop_location_type))})\n",
    "temp = tf['id']\n",
    "temp.to_csv(\"outputhack.csv\")\n",
    "\n",
    "tf=tf.drop(['id'],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = df['pricing_category']  #df.iloc[:,-1]\n",
    "y_train = y_train.astype(float)\n",
    "X_train = df.drop('pricing_category', axis=1)\n",
    "\n",
    "X_test = tf\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn import metrics\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# model = XGBClassifier(n_estimators=400,max_depth = 3,min_child_weight=10,reg_lambda=1,learning_rate=0.1,subsample=0.9, colsample_bytree=0.6,objective= 'multi:softmax',nthread=4)\n",
    "model = GradientBoostingClassifier(n_estimators=100,learning_rate=0.1,max_depth=5,tol=0.001,subsample=0.9,min_impurity_decrease=0.1)\n",
    "# model.fit(X_train, y_train)\n",
    "\n",
    "# y_pred = model.predict(X_test)\n",
    "# accuracy = accuracy_score(y_test, y_pred)\n",
    "# print(\"Accuracy: %.2f%%\" % (accuracy * 100.0))\n",
    "\n",
    "# model = RandomForestClassifier(max_depth=13, random_state=0,n_estimators=100,n_jobs=-1)\n",
    "model.fit(X_train, y_train)\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "# y_train = df.iloc[:,-1]\n",
    "# y_train = y_train.astype(float)\n",
    "# X_train = df.drop('pricing_category', axis=1)\n",
    "\n",
    "# X_test = tf\n",
    "\n",
    "# clf = RandomForestClassifier(max_depth=20, random_state=0,n_estimators=100)\n",
    "# clf.fit(x_train,y_train)\n",
    "# y_pred=clf.predict(x_test)\n",
    "# print(\"Test Accuracy = \", accuracy_score(y_test, y_pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "abc = pd.DataFrame({'pricing_category':y_pred})\n",
    "k = temp.to_frame()\n",
    "final = k.join(abc)\n",
    "final.to_csv(\"outputhack.csv\",index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import OneHotEncoder, LabelEncoder\n",
    "\n",
    "df = pd.read_csv(\"train.csv\",sep=',')\n",
    "df['taxi_type']=df['taxi_type'].fillna(df['taxi_type'].value_counts().idxmax())\n",
    "\n",
    "taxi_type = pd.get_dummies(df['taxi_type'])\n",
    "df= pd.concat([df,taxi_type],axis=1)\n",
    "\n",
    "df['months_of_activity'] = df['months_of_activity'].fillna(df['months_of_activity'].mean()).astype(int)\n",
    "df['customer_score'] = df['customer_score'].fillna(df['customer_score'].mean())\n",
    "df['customer_score_confidence'] = df['customer_score_confidence'].fillna(df['customer_score_confidence'].value_counts().idxmax())\n",
    "\n",
    "customer_score_confidence = pd.get_dummies(df['customer_score_confidence'])\n",
    "# print(customer_score_confidence)\n",
    "df= pd.concat([df,customer_score_confidence],axis=1)\n",
    "\n",
    "\n",
    "df['drop_location_type'] = df['drop_location_type'].fillna(df['drop_location_type'].value_counts().idxmax())\n",
    "df['ratings_given_by_cust'] = df['ratings_given_by_cust'].fillna(df['ratings_given_by_cust'].mean())\n",
    "df['num_of_cancelled_trips'] = df['num_of_cancelled_trips'].fillna(math.ceil(df['num_of_cancelled_trips'].mean()))\n",
    "df['anon_var_1'] = df['anon_var_1'].fillna(math.ceil(df['anon_var_1'].mean())).astype(int)\n",
    "df['anon_var_2'] = df['anon_var_2'].fillna(math.ceil(df['anon_var_2'].mean()))\n",
    "df['anon_var_3'] = df['anon_var_3'].fillna(math.ceil(df['anon_var_3'].mean()))\n",
    "df['sex'] = df['sex'].map({'Female': 5, 'Male': 6})\n",
    "# abc = df['taxi_type'].unique()\n",
    "# df['taxi_type'] = df['taxi_type'].map({'A':0, 'B':1, 'C':2, 'D':3, 'E':4})\n",
    "# customer_score_confidence = df['customer_score_confidence'].unique()\n",
    "# customer_score_confidence.sort()\n",
    "# df['customer_score_confidence'] = df['customer_score_confidence'].map({customer_score_confidence[i-7]:i for i in range(7,7+len(customer_score_confidence))})\n",
    "drop_location_type = df['drop_location_type'].unique()\n",
    "drop_location_type.sort()\n",
    "df['drop_location_type'] = df['drop_location_type'].map({drop_location_type[i]:i for i in range(len(drop_location_type))})\n",
    "# df_new = df.filter(['taxi_type','customer_score_confidence','drop_location_type','sex','pricing_category'],axis=1)\n",
    "# df = df.drop(['id','taxi_type','customer_score_confidence','drop_location_type','sex','pricing_category'],axis=1)\n",
    "# # print(df_new)\n",
    "# df = preprocessing.minmax_scale(df,axis=1)\n",
    "# df = pd.DataFrame(df,columns=['distance','months_of_activity','customer_score','ratings_given_by_cust','num_of_cancelled_trips','anon_var_1','anon_var_2','anon_var_3'])\n",
    "# # df = stats.boxcox(df)\n",
    "# # df\n",
    "\n",
    "# df = pd.concat([df,df_new],axis=1)\n",
    "# df = df.drop(['anon_var_1'],axis=1)\n",
    "\n",
    "df['pricing_category']= df['pricing_category'].astype(float)\n",
    "df = df.drop(['id','taxi_type','customer_score_confidence'],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf=pd.read_csv(\"test.csv\",sep=\",\")\n",
    "tf['taxi_type']=tf['taxi_type'].fillna('B')\n",
    "\n",
    "taxi_type = pd.get_dummies(tf['taxi_type'])\n",
    "tf= pd.concat([tf,taxi_type],axis=1)\n",
    "\n",
    "\n",
    "tf['months_of_activity'] = tf['months_of_activity'].fillna(df['months_of_activity'].mean())\n",
    "tf['customer_score'] = tf['customer_score'].fillna(df['customer_score'].mean())\n",
    "tf['customer_score_confidence'] = tf['customer_score_confidence'].fillna('B')\n",
    "\n",
    "customer_score_confidence = pd.get_dummies(tf['customer_score_confidence'])\n",
    "tf= pd.concat([tf,customer_score_confidence],axis=1)\n",
    "\n",
    "\n",
    "tf['drop_location_type'] = tf['drop_location_type'].fillna('A')\n",
    "tf['ratings_given_by_cust'] = tf['ratings_given_by_cust'].fillna(df['ratings_given_by_cust'].mean())\n",
    "tf['num_of_cancelled_trips'] = tf['num_of_cancelled_trips'].fillna(math.ceil(df['num_of_cancelled_trips'].mean()))\n",
    "tf['anon_var_1'] = tf['anon_var_1'].fillna(math.ceil(df['anon_var_1'].mean()))\n",
    "tf['anon_var_2'] = tf['anon_var_2'].fillna(math.ceil(df['anon_var_2'].mean()))\n",
    "tf['anon_var_3'] = tf['anon_var_3'].fillna(math.ceil(df['anon_var_3'].mean()))\n",
    "\n",
    "# taxi_type = df['taxi_type'].unique()\n",
    "# taxi_type.sort()\n",
    "# df['taxi_type'] = df['taxi_type'].map({taxi_type[i]:i for i in range(len(taxi_type))})\n",
    "\n",
    "\n",
    "# tf['taxi_type'] = tf['taxi_type'].map({'A':0, 'B':1, 'C':2, 'D':3, 'E':4})\n",
    "tf['sex'] = tf['sex'].map({'Female': 5, 'Male': 6})\n",
    "# customer_score_confidence = tf['customer_score_confidence'].unique()\n",
    "# customer_score_confidence = customer_score_confidence[~(pd.isnull(customer_score_confidence))]\n",
    "# customer_score_confidence.sort()\n",
    "# tf['customer_score_confidence'] = tf['customer_score_confidence'].map({customer_score_confidence[i-7]:i for i in range(7,7+len(customer_score_confidence))})\n",
    "drop_location_type = tf['drop_location_type'].unique()\n",
    "drop_location_type.sort()\n",
    "#print(drop_location_type)\n",
    "tf['drop_location_type'] = tf['drop_location_type'].map({drop_location_type[i]:i for i in range(len(drop_location_type))})\n",
    "temp = tf['id']\n",
    "temp.to_csv(\"output.csv\")\n",
    "\n",
    "tf = tf.drop(['id','taxi_type','customer_score_confidence'],axis=1)\n",
    "# tf = preprocessing.minmax_scale(tf,axis=1)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
